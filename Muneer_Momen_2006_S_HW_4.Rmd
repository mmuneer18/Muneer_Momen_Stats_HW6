---
title: "CMDA-2006 Statistics Homework 4"
author: "Momen Muneer"
output:
  pdf_document:
    highlight: haddock
    latex_engine: xelatex
geometry: margin=0.5in
urlcolor: blue
header-includes:
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage{xcolor}
---

```{r setup, include=FALSE}
# This is the setup chunk
#  Here you can set global options for the entire document

library(knitr) # I recommend doing this

# Although you can call functions from a library using the following notation
#  without loading the entire library.
knitr::opts_chunk$set(echo = TRUE, 
                      comment = NA, # Recommended
                      fig.path = "./figures/",  # Store all figures here in relative path (make the folder first)
                      fig.align = "center",
                      fig.width = 7,
                      fig.height = 7,
                      message = FALSE, # Turn off load messages
                      warning = FALSE # Turn off warnings
                      )

```

## R Markdown


## Problem 1

```{r problem_1}

# Observed and expected counts (sum should be 137 each)
obs   <- c(18, 28, 14, 7, 11, 11, 10, 8, 30)
expct <- c(23, 18, 16, 13, 11,  9, 20, 8, 19)

sum(obs); sum(expct)  

# Manual chi-square, df, and p-value
chi_sq_1 <- sum((obs - expct)^2 / expct)
dfree_1  <- length(obs) - 1
pval_1   <- 1 - pchisq(chi_sq_1, dfree_1)

chi_sq_1; dfree_1; pval_1

# Verify with chisq.test using expected proportions
chisq.test(x = obs, p = expct / sum(expct))

```
The chi-square test produced a p-value of about 0.028, which is below the 0.05 significance level. This means we reject the null hypothesis and conclude that the observed vehicle arrival times differ from the theoretical model. In simpler terms, the model does not explain the real traffic patterns in Riyadh very well.



```{r problem_2}

# Observed counts (Yellow Round, Yellow Wrinkled, Green Round, Green Wrinkled)
observed <- c(298, 107, 92, 27)
ratio    <- c(9, 3, 3, 1)
expected <- sum(observed) * ratio / sum(ratio)

observed; round(expected, 2)

chi_sq_2 <- sum((observed - expected)^2 / expected)
dfree_2  <- length(observed) - 1
pval_2   <- 1 - pchisq(chi_sq_2, dfree_2)

chi_sq_2; dfree_2; pval_2

# Check with chisq.test
chisq.test(x = observed, p = ratio / sum(ratio))

```
Part a) The chi-square test conditions are satisfied because the data are independent counts of four plant types, and all expected values are above 5.

Part b) H₀: The phenotypes follow a 9:3:3:1 ratio. Hₐ: The phenotypes do not follow that ratio.

Part c) Expected counts are approximately 294.75, 98.25, 98.25, and 32.75.

Part d) The test statistic is about χ² = 2.22 with 3 degrees of freedom and a p-value of 0.528.

Part e) Since p > 0.05, we fail to reject H₀, meaning the observed results are consistent with Mendel’s predicted 9:3:3:1 ratio.


```{r problem_3}

# Table from the prompt (rows = Statistics grade, cols = OR grade)
grades <- matrix(c(
  25,  6, 17, 13,   # Stats A
  17, 16, 15,  6,   # Stats B
  18,  4, 18, 10,   # Stats C
  10,  8, 11, 20    # Stats Other
), nrow = 4, byrow = TRUE)

rownames(grades) <- c("A","B","C","Other")         # Statistics grades on x-axis
colnames(grades) <- c("OR A","OR B","OR C","Other")# OR grade categories

grades   # raw counts table 

```

# (a) 

```{r}
row_perc <- round(prop.table(grades, 1) * 100, 2)  # each row sums to 100%
row_perc                                        

```
Each row shows the OR grade mix within a given Statistics grade.

# (b) 

```{r}
barplot(
  t(prop.table(grades, 1)),      
  beside = FALSE,                # stacked (not side-by-side)
  ylim = c(0, 1),
  main = "Relative Frequency of OR Grades by Statistics Grade",
  xlab = "Statistics Grade",
  ylab = "Proportion",
  legend.text = TRUE,            # legend with OR categories
  args.legend = list(x = "topright", inset = 0.02)
)

```

The stacked bars differ across Stats grades

# (c) 

```{r}

chi <- chisq.test(grades, correct = FALSE)
chi_stat <- as.numeric(chi$statistic)
dfree_3  <- as.numeric(chi$parameter)
p_exact  <- 1 - pchisq(chi_stat, dfree_3)

chi_stat; dfree_3; p_exact

```
H₀: Stats and OR grades are independent; Hₐ: they are related. We get χ² ≈ 25.55, df = 9, p ≈ 0.0024; since p < 0.01, we reject H₀ and conclude the grades are significantly related.

## Problem 4

```{r problem_4}

# Counts: rows = group, cols = CHD yes/no
whi <- matrix(c(
  1000, 18541,   # Intervention: Yes, No
  1549, 27745    # Control:      Yes, No
), nrow = 2, byrow = TRUE)

rownames(whi) <- c("Intervention","Control")
colnames(whi) <- c("CHD Yes","CHD No")

whi; sum(whi)

```

# Part a)

```{r}

chi4 <- chisq.test(whi, correct = FALSE)
chi4$statistic    # chi-square value
chi4$parameter    # df = 1
p_chi <- 1 - pchisq(chi4$statistic, df = chi4$parameter)
p_chi

```

At the 5% level, the chi-square test gives χ² ≈ 0.687 with 1 degree of freedom and p ≈ 0.407, so we fail to reject H₀. In context, CHD incidence appears independent of group; the intervention did not show a statistically significant difference.


# Part b)

```{r}

p1 <- whi[1,1] / sum(whi[1,])           
p2 <- whi[2,1] / sum(whi[2,])           
p_pool <- (whi[1,1] + whi[2,1]) / sum(whi)
se <- sqrt(p_pool * (1 - p_pool) * (1/sum(whi[1,]) + 1/sum(whi[2,])))
z_stat <- (p1 - p2) / se
p_z <- 2 * (1 - pnorm(abs(z_stat)))     # two-sided p-value


```

The pooled two-sample z-test yields z ≈ −0.829 and a two-sided p ≈ 0.407, leading to the same conclusion. There is no statistically significant difference in CHD proportions between intervention and control.


# Part c)

```{r}

z_stat^2

```

We find z² ≈ 0.687, which equals the chi-square statistic from part (a). As expected for a 2×2 table (without continuity correction), χ² = z² and the p-values agree.

Conclusion: There’s no statistical evidence that the intervention changed CHD incidence; the groups’ rates are essentially the same.


## Problem 5

```{r problem_5}

x <- 45  # correct choices
n <- 75  # trials
p0 <- 1/3

# One-sided test
prop_res  <- prop.test(x, n, p = p0, alternative = "greater", correct = FALSE)
prop_res

binom.test(x, n, p = p0, alternative = "greater")

```
(a)
Null: p = 1/3
Alternative: p > 1/3
The one-sided p-value is extremely small (about 2 × 10^−6), so at α=0.02 we reject H0: the squirrel is performing better than chance and can distinguish red from white.

(b) A directional (one-tailed) test is right here because we only care if performance is better than chance; doing worse than chance wouldn’t indicate color discrimination—it would just look like random guessing.


**Honor Code Statement:**  
“I have neither given nor received unauthorized assistance on this assignment. The work I am presenting is ultimately my own.”






